---
title: | 
 \textbf{Identifying Key Moderators and Predictors of Smoking Cessation in Adults with Major Depressive Disorder}

 \vspace{1cm} 
subtitle: 
 "Practical Data Analysis - Project 2: Regression Analysis"
author: "Aristofanis Rontogiannis"
date: "2024-11-04"
output:
  pdf_document: 
    latex_engine: xelatex
    keep_tex: true

link-citations: yes
abstract: |
  **Purpose**: This project evaluates the efficacy of smoking cessation treatments among adults with Major Depressive Disorder (MDD), focusing on identifying baseline factors that moderate and predict treatment success. This analysis aims to clarify the role of both behavioral and pharmacological interventions, examining interactions between participant characteristics and treatment components.

  **Methods**: Using data from a randomized, placebo-controlled trial, we assessed the effectiveness of Behavioral Activation (BA) and standard treatment (ST), each paired with either varenicline or a placebo, in supporting smoking cessation. Two statistical approaches-- Lasso regression and Elastic Net Regression with 10-fold cross validation-- were employed to identify significant moderators and predictors of abstinence at the end of treatment, based on a sample of 300 adult smokers with current or past MDD.
    
  **Results**: The findings indicate that specific baseline characteristics, including FTCD score (a measure of nicotine dependence) and Nicotine Metabolism Ratio (NMR), significantly influence treatment outcomes. FTCD score was associated with lower abstinence rates, while a higher NMR was linked to greater likelihood of cessation. These predictors were consistently identified across models, suggesting a robust relationship between these factors and smoking cessation outcomes.

  **Conclusions**: This study supports the need for tailored smoking cessation strategies for individuals with MDD, highlighting the potential of combining behavioral and pharmacological treatments based on individual characteristics. By identifying critical predictors and moderators, the findings provide a foundation for developing more personalized and effective cessation programs for this high-risk population.
bibliography: References.bib
---

# Introduction

This project is a collaboration with Dr. George Papandonatos from the Department of Biostatistics at Brown University. This project examines the effectiveness of smoking cessation treatments for adults with major depressive disorder (MDD), a group that encounters unique challenges when trying to quit smoking. People with MDD often smoke more heavily, have a stronger dependence on nicotine, and face more intense withdrawal symptoms than those without MDD. While varenicline, a medication for quitting smoking, has shown promising results, psychological approaches that address depression-related issues, like behavioral activation (BA), might further enhance quit rates for this group.

This project uses data from a randomized, placebo-controlled study (@hitsman2023efficacy) that compared behavioral activation with standard treatment (ST), both combined with either varenicline or a placebo. The study allows us to explore how baseline characteristics may affect treatment success at the end of treatment (EOT), including 300 adult smokers who have current or past MDD. Specifically, we aim to identify baseline factors that may influence the effectiveness of behavioral treatments and predict abstinence, considering both behavioral and medication-based therapies.

The findings from this research could lead to more effective, personalized smoking cessation strategies for people with MDD, addressing their specific challenges and improving treatment outcomes.


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                  message = FALSE,
                  warning = FALSE,
                  error = FALSE)

library(summarytools)
library(ggplot2)
library(knitr)
library(kableExtra)
library(GGally)
library(patchwork)
library(dplyr)
library(reshape2)
library(tidyr)
library(grid)
library(lubridate)
library(gtsummary)
library(gt)
library(ggcorrplot)
library(glmnet)
library(MASS)
library(pROC)
library(gridExtra)
library(VIM)
library(mice)
library(leaps)
library(ggplot2)
library(ggmosaic)
library(ggbeeswarm)
library(ggdist)
library(cowplot)
library(caret)
```

# Data Overview

As shown in Table 1 below, participant characteristics were stratified by four treatment combination-- behavioral activation with placebo (BASC+placebo), standard treatment with placebo (ST+placebo), behavioral activation with varenicline (BASC+varenicline), and standard treatment with varenicline (ST+varenicline)-- and summarized by treatment group in three primary areas: demographics, smoking characteristics, and psychiatric characteristics. 

In the demographics section, participant variables such as age, sex, race, income, and education level were included. Age was summarized as a continuous variable using mean and standard deviation, while categorical variables like sex, race, income, and education level were presented with counts and percentages for each treatment group. This section provides an overview of the baseline demographic distribution across the four treatment conditions.

Smoking-related characteristics were summarized to include baseline measures of cigarette consumption, such as cigarettes per day, FTCD score, and readiness to quit smoking. Continuous variables like cigarettes per day and FTCD score were summarized with mean and standard deviation, while categorical variables, such as whether participants smoked within five minutes of waking up, were presented with counts and percentages. This section helps illustrate smoking behaviors across the different treatment groups.

Psychiatric characteristics were also summarized to capture information related to mental health, such as anhedonia (measured by the SHAPS score), presence of other DSM-5 diagnoses, use of antidepressant medication, and current versus past MDD status. Continuous variables, like the SHAPS score, were summarized by mean and standard deviation, while categorical variables, like the presence of other DSM-5 diagnoses, were displayed with counts and percentages. This section highlights the psychiatric characteristics of participants across treatment groups.

With those three sections, Table 1 provides an overall snapshot of participant characteristics by treatment group and by overall sample. This table is organized to present a clear and comprehensive view of the data, allowing for straightforward comparisons across treatment groups and providing context for further analyses on treatment outcomes.

```{r}
#Read main data set 
data<-read.csv("project2.csv") 

# Data processing
data = data  %>%
  # create race variable
  mutate(race = factor(case_when(
    NHW == 1 ~ "Non-Hispanic White",
    Black == 1 ~ "Black",
    Hisp == 1 ~ "Hispanic",
    TRUE ~ "Other"  # Handle cases where none of the above conditions are met
  ), levels = c("Non-Hispanic White", "Black", "Hispanic", "Other"))) %>%
  # create treatment categories
  mutate(treatment_cat = factor(case_when(BA == 1 & Var == 0 ~ "BASC+placebo",
                                   BA == 0 & Var == 0 ~ "ST+placebo",
                                   BA == 1 & Var == 1 ~ "BASC+varenicline",
                                   BA == 0 & Var == 1 ~ "ST+varenicline"))) %>%
  # Change variables attributes to be only Numeric or Factor at the end
  #Factor
  mutate(
    abst = factor(abst),
    Var = factor(Var),
    BA = factor(BA),
    sex_ps = factor(sex_ps),
    ftcd.5.mins = factor(ftcd.5.mins),
    otherdiag = factor(otherdiag),
    antidepmed = factor(antidepmed),
    mde_curr = factor(mde_curr),
    Only.Menthol = factor(Only.Menthol),
    edu = factor(edu, levels = c(1, 2, 3, 4, 5)),
    inc = factor(inc, levels = c(1, 2, 3, 4, 5))
  ) %>%
 #Numeric (except id)
  mutate(across(
    .cols = where(is.numeric) & !all_of("id"),
    .fns = as.numeric
  ))

```


\newpage
\begin{landscape}
```{r}
# Summary Table
table1_data = data %>%
  mutate(edu = factor(edu, levels = c(1, 2, 3, 4, 5),
                 labels = c("     Grade school",
                            "     Some high school",
                            "     High school graduate or GED",
                            "     Some college/technical school",
                            "     College graduate")),
    inc = factor(inc, levels = c(1, 2, 3, 4, 5),
                 labels = c("     Less than $20,000",
                            "     $20,000–$35,000",
                            "     $35,001–$50,000",
                            "     $50,001–$75,000",
                            "     More than $75,000")),
    race = factor(race, labels = c("    Non-Hispanic White",
                                   "    Black",
                                   "    Hispanic",
                                   "    Other"))
    )

# Demographics table
demographics_table <- table1_data %>%
  dplyr::select(
    treatment_cat,
    age_ps,
    sex_ps,
    race,
    inc,
    edu
  ) %>%
  tbl_summary(
    by = treatment_cat,
    label = list(
      age_ps = "Age (years)",
      sex_ps = "Sex (Female)",
      race = "Race",
      inc = "Income",
      edu = "Education"
    ),
    type = list(
      age_ps ~ "continuous",
      sex_ps ~ "dichotomous",
      race ~ "categorical",
      inc ~ "categorical",
      edu ~ "categorical"),
    value = list(
      sex_ps ~ "2"),
    statistic = list(all_continuous() ~ "{mean} ({sd})", 
                     all_categorical() ~ "{n} ({p}%)"),
    digits = all_continuous() ~ 1,
    missing = "no"
  ) %>% add_overall() 


# Smoking table
smoking_table <- table1_data %>%
  dplyr::select(
    treatment_cat,
    cpd_ps,
    ftcd_score,
    ftcd.5.mins,
    bdi_score_w00,
    crv_total_pq1,
    hedonsum_n_pq1,
    hedonsum_y_pq1,
    Only.Menthol,
    readiness,
    NMR
  ) %>%
  tbl_summary(
    by = treatment_cat,
    label = list(
      cpd_ps = "Cigarettes per day at baseline phone survey",
      ftcd_score = "FTCD score at baseline",
      ftcd.5.mins = "Smoking within 5 mins of waking up (Yes)",
      bdi_score_w00 = "BDI score at baseline",
      crv_total_pq1 = "Cigarette reward value at baseline",
      hedonsum_n_pq1 = "Pleasurable Events Scale - substitute reinforcers",
      hedonsum_y_pq1 = "Pleasurable Events Scale - complementary reinforcers",
      Only.Menthol = "Exclusive Mentholated Cigarette User (Yes)",
      readiness = "Readiness to quit smoking",
      NMR = "Nicotine Metabolism Ratio"
    ), type = list(
      cpd_ps ~ "continuous",
      ftcd_score ~ "continuous",
      ftcd.5.mins ~ "dichotomous",
      bdi_score_w00 ~ "continuous",
      crv_total_pq1 ~ "continuous",
      hedonsum_n_pq1 ~ "continuous",
      hedonsum_y_pq1 ~ "continuous",
      NMR ~ "continuous",
      Only.Menthol ~ "dichotomous",
      readiness ~ "continuous"),
    value = list(
      Only.Menthol ~ "1",
      ftcd.5.mins ~ "1"),
    statistic = list(all_continuous() ~ "{mean} ({sd})", all_categorical() ~ "{n} ({p}%)"),
    digits = all_continuous() ~ 1,
    missing = "no"
  ) %>% add_overall()

# Psychiatric table
psychiatric_table <- table1_data %>%
  dplyr::select(
    treatment_cat,
    shaps_score_pq1,
    otherdiag,
    antidepmed,
    mde_curr
  ) %>%
  tbl_summary(
    by = treatment_cat,
    label = list(
      shaps_score_pq1 = "Anhedonia",
      otherdiag = "Other lifetime DSM-5 diagnosis (Yes)",
      antidepmed = "Taking antidepressant medication at baseline (Yes)",
      mde_curr = "Current vs past MDD (Yes)"
    ),
    type = list(shaps_score_pq1 ~ "continuous",
      otherdiag ~ "dichotomous",
      antidepmed ~ "dichotomous",
      mde_curr ~ "dichotomous"),
    value = list(otherdiag ~ "1",
      antidepmed ~ "1",
      mde_curr ~ "1"),
    statistic = list(all_continuous() ~ "{mean} ({sd})", 
                     all_categorical() ~ "{n} ({p}%)"),
    digits = all_continuous() ~ 1,
    missing = "no"
  ) %>% add_overall() 


# Merge tables
final_table <- tbl_stack(
  tbls = list(demographics_table, smoking_table, psychiatric_table),
  group_header = c("Demographics", "Smoking", "Psychiatric")
) %>%
  modify_caption("Participant characteristics by treatment and overall sample") %>%
  as_kable_extra(
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    format = "latex"
  ) %>%
  kable_styling(
    position = "center",
    latex_options = c("striped", "repeat_header"),
    stripe_color = "gray!15",
    font_size = 8
  )


final_table
```
\end{landscape}
\newpage


Additionally, to facilitate certain analyses, a new variable was created to consolidate education levels. The three lower levels of education (Grade school, Some high school and high school graduate or GED) were combined into a single category representing lower education levels. This aggregation simplifies the education variable, as those three levels contained a small amount of participants, allowing for broader categorical comparisons while retaining essential information on educational background.

## Data Missingness and Imputation

The missing data analysis involves examining the extent of missingness across variables in the dataset. A summary table was generated (Table 2), listing variables with missing values, the count of missing entries for each variable, and the corresponding percentage relative to the total sample size. For example, the variable with the highest missingness is the variable NMR (7%), followed by the variables crv_total_pq1 (6%) and readiness (5.67%). Variables with no missing values were excluded from this table for clarity. This missingness analysis is a critical step in data preparation, as it helps to address data quality issues and ensure that the dataset is ready for further statistical modeling and interpretation. The total percentage of missingness was around 20%. If we have deleted all the rows with missing data, we might have lost a significant portion of our dataset, which could reduce the statistical power of our analyses and lead to biased estimates.

```{r}
#Missingness Table
# Calculate missing values for each variable
missing_summary <- data %>%
  summarise(across(everything(), ~ sum(is.na(.)), .names = "missing_{col}")) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Number") %>%
  mutate(Pct = (Number / nrow(data)) * 100) %>%
  filter(Number > 0)  # Exclude variables with 0 missingness

# Define a named vector with old and new names for variables
variable_names <- c(
  "inc" = "Income",
  "ftcd_score" = "FTCD Score",
  "crv_total_pqr" = "Cigarette reward at baseline",
  "shaps_score_pqi" = "Anhedonia",
  "NMR" = "Nicotine MEtabolism Ratio",
  "Only.Menthol" = "Exclusive Mentholated Cigarette User",
  "readiness" = "Baseline readiness to quit smoking"
)

# Rename variables in the summary table
missing_summary <- missing_summary %>%
  mutate(Variable = recode(Variable, !!!variable_names))

# Load knitr for table formatting (optional)
library(knitr)

# Create and display the table
missing_summary %>%
  arrange(desc(Pct)) %>%
  mutate(Pct = sprintf("%.2f%%", Pct)) %>%
  kable(col.names = c("Variable", "Number", "Pct"), caption = "Summary 
        of Missing Values")
```

```{r}
# Create a new variable that contains the 3 first levels of edu
data <- data %>%
  mutate(edu_merged = factor(case_when(
    edu %in% c("1", "2", "3") ~ "1",
    edu == "4" ~ "2",
    edu == "5" ~ "3"
  )))


```

To handle missing data, the Multiple Imputation by Chained Equations (MICE) method was applied. MICE is an iterative process that generates multiple plausible datasets by imputing missing values based on the observed data structure. Here, we used predictive mean matching (PMM) as the imputation method. PMM is advantageous as it imputes realistic values by using observed values from other participants with similar predictive values.

```{r}
# MICE 
# Perform MICE imputation
data_mice <- mice(data, m = 5
                  , method = "pmm", maxit = 50, seed = 58, printFlag= FALSE)

data_mice_4 = complete(data_mice, action = 4)

```

## Exploration of potential interactions
As part of the Explanatory Data Analysis, we want to examine the relationship between menthol cigarette use and race. We created a contingency table to display the frequencies of menthol and non-menthol use across racial categories, and then performed a Chi-square test to assess whether there is a statistically significant association between race and menthol cigarette use.

The Chi-square test produced a very low p-value, indicating a statistically significant association between race and menthol cigarette use. This result suggests that menthol cigarette usage depends on race, as there appears to be a notable relationship between the two variables.

We can easily observe from Table 3 that Black individuals have a preference for menthol cigarettes over regular non-menthol ones (130 out of 157 people).

```{r}
# Check the relationship between Menthol Cigarettes and Race
table_race_menthol <- table(data_mice_4$race, data_mice_4$Only.Menthol)

# Chi-square test
chi_square_test <- chisq.test(table_race_menthol) #p-value too small
#We reject the null hypothesis (which is there is no association)

chi_square_test_note <- paste0(
  sprintf("Chi-Square Statistic: %.4f", chi_square_test$statistic),
  sprintf(", p-value : Approaching %.4f", chi_square_test$p.value)
)

kable(table_race_menthol,
      caption = "Contingency Table of Only Menthol Use and Race",
      col.names = c("Non-Menthol", "Menthol"),
      row.names = TRUE,
      format = "markdown")  %>%
  footnote(chi_square_test_note, footnote_as_chunk = FALSE)

```


Additionally, we examine the relationships between education, income, race, and FTCD scores through mosaic and raincloud plots.


```{r,fig.width = 10, fig.height = 4, out.width = "80%", fig.align = "center"}
# Mosaic between education, income
# mosaic = vcd::mosaic(~ inc + edu_merged, data = data_mice_4, shade = TRUE, 
#                      legend = TRUE, labeling = labeling_values) 

data_viz = data_mice_4 %>%
  mutate(
    edu_merged = recode(factor(edu_merged),
                        `1` = "<= High school",
                        `2` = "Some college",
                        `3` = "College graduate"),
    inc = recode(factor(inc),
                 `1` = "Less than $20,000",
                 `2` = "$20,000–$35,000",
                 `3` = "$35,001–$50,000",
                 `4` = "$50,001–$75,000",
                 `5` = "More than $75,000"),
    race = factor(race, levels = c("Non-Hispanic White",
                                   "Black",
                                   "Hispanic",
                                   "Other"))
    )

# Heatmap between education, income
heatmap1 = ggplot(data = data_viz) +
  geom_mosaic(aes(weight = 1, x = product(inc), fill = edu_merged)) +
  labs(
    title = "           Mosaic Plot between Education and Income",
    x = "Income",
    y = "Education"
  ) +
  scale_fill_manual(values = c("slateblue3", "grey", "palevioletred")) + 
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

# Heatmap between race, education
heatmap2 = ggplot(data = data_viz) +
  geom_mosaic(aes(weight = 1, x = product(race), fill = edu_merged)) +
  labs(
    title = "Mosaic Plot between Education and Race",
    x = "Race",
    y = "Education"
  ) +
  scale_fill_manual(values = c("slateblue3", "grey", "palevioletred")) + 
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

# Beeswarm plot between Sex, NMR
#beeswarm = ggplot(data_mice_4, aes(x = sex_ps, y = NMR, color = sex_ps)) +
 # geom_beeswarm(size = 2, alpha = 0.7) +
  #labs(x = "Sex", y = "NMR", title = "Beeswarm Plot") +
  #theme_minimal() +
  #theme(legend.position = "none") +
  #scale_color_manual(values = c("slateblue3", "palevioletred"))



# Raincloud plot between edu, income
raincloud = ggplot(data_mice_4, aes(x = race, y = ftcd_score, fill = race)) +
  ggdist::stat_halfeye(adjust = 0.5, width = 0.6, .width = 0, 
                       justification = -0.2, point_colour = NA) +
  geom_boxplot(width = 0.1, outlier.shape = NA, alpha = 0.5) +
  geom_jitter(width = 0.1, alpha = 0.4) +
  coord_flip() +  # Flip coordinates for a horizontal layout
  labs(x = "Race", y = "FTCD Score", title = "Raincloud Plot") +
  theme_minimal() +
  scale_fill_manual(values = c("mediumblue","slateblue3", "grey", "palevioletred"))


combined_plot <- plot_grid(heatmap1, heatmap2, ncol = 2, align = "hv")
combined_plot

#combined_plot <- grid.arrange(mosaic, heatmap, beeswarm, raincloud, ncol = 2)
#combined_plot
#par(mfrow= c(2,2))
#mosaic

```

```{r,fig.width = 7, fig.height = 4, out.width = "80%", fig.align = "center"}
raincloud
```

**Mosaic Plot between Education and Income** This plot shows the distribution of education levels (edu_merged) across different income categories. We observe a gradient where higher education levels (coded in pink) tend to be associated with higher income levels, while lower education levels (in blue) were more concentrated in lower income brackets. This suggests a positive association between education and income.

**Mosaic Plot between Education and Race** This plot reveals the distribution of education levels across different racial groups. The distribution varies, with Non-Hispanic Whites showing a relatively higher proportion in the higher education categories, while other groups, such as Black and Hispanic, have a more balanced spread across the education levels. This pattern may indicate disparities in educational attainment across racial groups.

**Raincloud Plot for FTCD Score by Race** The raincloud plot shows the distribution and density of FTCD scores across racial groups. Non-Hispanic Whites have the highest density around higher FTCD scores, while other groups show a more varied distribution, with Hispanics and Black participants displaying lower scores overall. This visualization highlights potential differences in FTCD scores among racial groups, which may correlate with other socioeconomic factors.


# Methods

## Data separation and full model selection

To assess the model's performance and ensure its generalizability, we divided the data into training and test sets, with 70% of the observations assigned to the training set and 30% to the test set. This split allows us to train the model on one portion of the data and then evaluate its performance on a separate, unseen portion, reducing the risk of overfitting.

We ensured that the variables Var and BA are kept controlled in the model as those variables are crucial for investigating treatment interactions and their effect on abstinence. For objective one, we also added interaction terms between BA and baseline variables to explore potential moderator effects and other interaction terms, e.g., NMR:readiness and income:education, as reasonable covariates. For the second objective of this project, we considered baseline characteristics as potential predictors while keeping BA and Var controlled. Thus, for simplicity, no interaction terms were included in the full models.

## Lasso Regression

In this part of the analysis, we implemented a Lasso regression to identify potential moderators of the treatment effects on smoking abstinence. By using Lasso, we aim to reduce the model to a subset of variables and interaction terms that are most predictive of the outcome. Lasso is particularly useful here as it performs variable selection by penalizing the coefficients of less relevant variables, ultimately setting them to zero, which leads to a more interpretable model.

The training set was used to build the Lasso model, optimizing the selection of variables and interactions by identifying the subset that most effectively predicts smoking abstinence. Cross-validation on the training data determined the best penalty parameter (lambda), balancing the trade-off between model complexity and predictive accuracy.

After training the model, we evaluated it on the test set, providing an unbiased assessment of how well the selected variables and interactions generalize to new data. This approach ensures that the model is robust and capable of making reliable predictions beyond the original dataset.

The final model coefficients at the optimal lambda include only those variables and interactions with non-zero coefficients, which are presented in the resulting tables (Table 4 and Table 5). This selection helps identify significant moderators of smoking abstinence while maintaining a simpler model.

!!placeholder

!!placeholder

!!placeholder

!!placeholder

!!placeholder
!!placeholder

```{r}
# To identify the potential interaction terms for moderator effects
train_variables_dummy_include_names <- c(
  "Var1", "BA1", "age_ps", "sex_ps2", "inc2", "inc3",
  "inc4", "inc5", "edu_merged2", "edu_merged3",
  "raceBlack", "raceHispanic", "raceOther",
  "ftcd_score", "ftcd.5.mins1", "bdi_score_w00", "cpd_ps",
  "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",              
  "shaps_score_pq1", "otherdiag1", "antidepmed1",                  
  "mde_curr1", "NMR", "Only.Menthol1",                
  "readiness", 
  
  "BA1:mde_curr1",
  "BA1:age_ps", "BA1:sex_ps2",
  "BA1:raceBlack", "BA1:raceHispanic",
  "BA1:raceOther", "BA1:ftcd_score",
  "BA1:shaps_score_pq1","BA1:bdi_score_w00",
  "BA1:otherdiag1", "BA1:antidepmed1",
  "BA1:mde_curr1","BA1:NMR",
  "BA1:Only.Menthol1", "BA1:readiness", "BA1:cpd_ps",

  
  "Var1:BA1", 
  "Var1:age_ps", "Var1:sex_ps2",
  "Var1:raceBlack", "Var1:raceHispanic",
  "Var1:raceOther", "Var1:ftcd_score", "Var1:cpd_ps",
  
   "inc2:edu_merged2", "inc2:edu_merged3",
  "inc3:edu_merged2", "inc3:edu_merged3",
  "inc4:edu_merged2", "inc4:edu_merged3",
  "inc5:edu_merged2", "inc5:edu_merged3",
  "antidepmed1:readiness", "Only.Menthol1:readiness",
  "mde_curr1:readiness", "ftcd.5.mins1:readiness",
  "bdi_score_w00:readiness", "Var1:shaps_score_pq1", "shaps_score_pq1:mde_curr1",
  "sex_ps2:ftcd_score", "raceBlack:ftcd_score",
  "raceHispanic:ftcd_score", "raceOther:ftcd_score",
  "age_ps:ftcd_score", "sex_ps2:Only.Menthol1", 
  "raceBlack:Only.Menthol1", "raceHispanic:Only.Menthol1", 
  "raceOther:Only.Menthol1",
  "inc2:Only.Menthol1", "inc3:Only.Menthol1",
  "inc4:Only.Menthol1", "inc5:Only.Menthol1",
  "edu_merged2:Only.Menthol1", "edu_merged3:Only.Menthol1",
  "sex_ps2:NMR", "age_ps:NMR", "cpd_ps:NMR",
  "NMR:readiness", "ftcd_score:NMR"
)


```

```{r helper-functions}
variable_names <- c("Var", "BA", "age_ps", "sex_ps", "inc", "edu_merged", "race",
                     "ftcd_score", "ftcd.5.mins", "bdi_score_w00", "cpd_ps",
                     "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",
                     "shaps_score_pq1", "otherdiag", "antidepmed", "mde_curr",
                     "NMR", "Only.Menthol", "readiness")

# Helper function to perform model fitting
fit_models <- function(data) {
  # Define predictors and outcome
 
  outcome <- data$abst
  variables <- data[, variable_names]
  # for Lasso (to break down factors with >2 levels)
  variables_dummy <- model.matrix( ~ 0 + ., data = variables)
  # remove the extra reference group
  variables_dummy <- variables_dummy[, -which(colnames(variables_dummy) ==
                                                "Var0")]
 

  # Split into train and test sets
  set.seed(58)
  train_index <- createDataPartition(outcome, p = 0.7, list = FALSE)
  train_data <- data[train_index, ]
  train_outcome = train_data$abst
  test_data <- data[-train_index, ]
  test_outcome = test_data$abst
 
  train_variables_dummy <- variables_dummy[train_index, ]
  test_variables_dummy <- variables_dummy[-train_index, ]
 
  # ^2 generates all pairwise interactions
  train_variables_dummy_df <- as.data.frame(train_variables_dummy)
  train_variables_dummy_full_interactions <- model.matrix( ~ . ^ 2, data = train_variables_dummy_df)
 
  test_variables_dummy_df <- as.data.frame(test_variables_dummy)
  test_variables_dummy_full_interactions <- model.matrix( ~ . ^ 2, data = test_variables_dummy_df)
 
  train_variables_dummy_include =
    train_variables_dummy_full_interactions[, train_variables_dummy_include_names]
  test_variables_dummy_include =
    test_variables_dummy_full_interactions[, train_variables_dummy_include_names]
 
  # Set penalty factors to enforce keeping Var and BA
  # Initialize penalty factors to 1 for all variables
  penalty_factors <- rep(1, ncol(train_variables_dummy_include))

  # Identify columns corresponding exactly to "Var1" and "BA1" (not their interactions)
  var1_col <- grep("^Var1$", colnames(train_variables_dummy_include))
  ba1_col <- grep("^BA1$", colnames(train_variables_dummy_include))
 
  penalty_factors[c(var1_col, ba1_col)] <- 0
  names(penalty_factors) <- colnames(train_variables_dummy_include)

  # Fit Elastic Net model
  enet_model <- cv.glmnet(
    as.matrix(train_variables_dummy_include),
    train_outcome,
    penalty.factor = penalty_factors,
    alpha = 0.5,
    family = "binomial",
    nfold = 10
  )

  # Fit Lasso model (alpha = 1)
  lasso_model <- cv.glmnet(
    as.matrix(train_variables_dummy_include),
    train_outcome,
    penalty.factor = penalty_factors,
    alpha = 1,
    family = "binomial",
    nfold = 10
  )

  list(
    elastic_net = enet_model,
    lasso = lasso_model
  )
}
```

```{r fit-multiple-imputed}
# Fit models across imputed datasets
aim1_results <- list()
for (i in 1:5) {
  dataset <- complete(data_mice
                      , action = i)
  aim1_results[[i]] <- fit_models(dataset)
}
```



```{r}
# Initialize lists to store coefficients for Elastic Net and Lasso
elastic_net_coefs <- lapply(aim1_results, function(res) coef(res$elastic_net, s = res$elastic_net$lambda.min))
lasso_coefs <- lapply(aim1_results, function(res) coef(res$lasso, s = res$lasso$lambda.min))

# Function to process coefficients for averaging and selection count
process_coefs <- function(coefs_list) {
  # Combine coefficients into a matrix
  coefs_matrix <- do.call(cbind, lapply(coefs_list, function(coef) as.numeric(coef)))
  rownames(coefs_matrix) <- rownames(coefs_list[[1]])
 
  # Count non-zero selections for each variable
  selection_counts <- rowSums(coefs_matrix != 0)
 
  # Compute the average of coefficients only when selected (non-zero)
  averaged_coefs <- rowSums(coefs_matrix) / selection_counts
  averaged_coefs[is.na(averaged_coefs)] <- 0  # Handle cases where selection_counts is 0
 
  # Create result table
  result_table <- data.frame(
    variable = rownames(coefs_matrix),
        SelectionTimes = selection_counts,
    AverageCoefficient = averaged_coefs
  ) %>%
    filter(SelectionTimes > 0)  # Keep only variables selected at least once
 
  return(result_table)
}

# Process Elastic Net and Lasso coefficients
result_table_enet <- process_coefs(elastic_net_coefs)
result_table_lasso <- process_coefs(lasso_coefs)

```


```{r}
# Calculate OR for each coefficient for each method and rename columns correctly
enet_df <- result_table_enet %>%
  rename(`Selection Times` = SelectionTimes) %>%
  rename(`Elastic Net Average Coef` = AverageCoefficient) %>%
  mutate(`Elastic Net Average OR` = exp(`Elastic Net Average Coef`))

lasso_df <- result_table_lasso %>%
  rename(`Selection Times` = SelectionTimes) %>%
  rename(`Lasso Average Coef` = AverageCoefficient) %>%
  mutate(`Lasso OR` = exp(`Lasso Average Coef`))



# Merge all data frames based on variable names
combined_df <- full_join(lasso_df, enet_df, by = "variable") %>%
  mutate(across(where(is.numeric), ~ round(.x, 4))) 

# Remove the intercept row
combined_df <- combined_df[combined_df$variable != "(Intercept)", ]

# Standardize interaction terms by sorting them alphabetically
combined_df <- combined_df %>%
  mutate(
    variable = sapply(variable, function(x) {
      terms <- unlist(strsplit(x, ":"))
      if (length(terms) > 1) {
        paste(sort(terms), collapse = ":")
      } else {
        x
      }
    })
  )

# Combine rows with the same standardized interaction term names
combined_df <- combined_df %>%
  group_by(variable) %>%
  summarize(across(everything(), ~ ifelse(is.numeric(.), sum(as.numeric(.), na.rm = TRUE), .))) %>%
  ungroup()

# Replace zeroes and any remaining NAs with an empty space for readability
combined_df <- combined_df %>%
  mutate(across(where(is.numeric), ~ ifelse(. == 0, "", .))) %>%
  replace(is.na(.), " ")

# Display the final combined table with grouped headers
combined_df %>%
  kable(row.names = F,
        col.names = c("Variable", "Selection Times","Average Coef", "OR", "Selection Times", "Average Coef", "OR"),
        caption = "Summary of Average Coefficients and Odds Ratios for Potential Moderator Effects across Model Selection Methods") %>%
  add_header_above(c(" " = 1, "Lasso" = 3, "Elastic Net" = 3)) %>%
  kable_styling(full_width = F, position = "center", font_size = 9)

```


```{r}
# Initialize lists to store results for each imputation
roc_results_enet <- list()
calib_results_enet <- list()
auc_values_enet <- list()

roc_results_lasso <- list()
calib_results_lasso <- list()
auc_values_lasso <- list()

num_cuts <- 10  # Number of bins for calibration

for (i in 1:5) {
  dataset <- complete(data_mice, action = i)
 
  # Split the dataset into training and test sets
  set.seed(58)
  train_index <- createDataPartition(dataset$abst, p = 0.7, list = FALSE)
  train_data <- dataset[train_index, ]
  test_data <- dataset[-train_index, ]
 
  # Prepare predictors and outcome for test set
  test_variables_dummy <- model.matrix(~ 0 + ., data = test_data[, variable_names])
  test_variables_dummy <- test_variables_dummy[, -which(colnames(test_variables_dummy) == "Var0")]
  test_variables_dummy_full_interactions <- model.matrix(~ . ^ 2, data = as.data.frame(test_variables_dummy))
  test_variables_dummy_include <- test_variables_dummy_full_interactions[, train_variables_dummy_include_names]
  test_outcome <- test_data$abst

  # Predict probabilities for Elastic Net
  predicted_prob_enet <- as.numeric(predict(aim1_results[[i]]$elastic_net,
                                            newx = as.matrix(test_variables_dummy_include),
                                            s = "lambda.min", type = "response"))
 
  # Predict probabilities for Lasso
  predicted_prob_lasso <- as.numeric(predict(aim1_results[[i]]$lasso,
                                             newx = as.matrix(test_variables_dummy_include),
                                             s = "lambda.min", type = "response"))

  # Compute ROC and AUC for Elastic Net
  roc_enet <- roc(test_outcome, predicted_prob_enet)
  roc_results_enet[[i]] <- data.frame(
    Specificity = rev(roc_enet$specificities),
    Sensitivity = rev(roc_enet$sensitivities)
  )
  auc_values_enet[[i]] <- auc(roc_enet)  # Store AUC separately
 
  # Compute ROC and AUC for Lasso
  roc_lasso <- roc(test_outcome, predicted_prob_lasso)
  roc_results_lasso[[i]] <- data.frame(
    Specificity = rev(roc_lasso$specificities),
    Sensitivity = rev(roc_lasso$sensitivities)
  )
  auc_values_lasso[[i]] <- auc(roc_lasso)  # Store AUC separately

 
  # Calibration for Elastic Net
  calib_data_enet <- data.frame(
    prob = predicted_prob_enet,
    bin = cut(predicted_prob_enet, breaks = num_cuts),
    class = as.numeric(test_outcome) - 1
  )
  calib_results_enet[[i]] <- calib_data_enet %>%
    group_by(bin) %>%
    summarise(
      observed = mean(class),
      predicted = mean(prob),
      se = sqrt(observed * (1 - observed) / n())
    )
 
  # Calibration for Lasso
  calib_data_lasso <- data.frame(
    prob = predicted_prob_lasso,
    bin = cut(predicted_prob_lasso, breaks = num_cuts),
    class = as.numeric(test_outcome) - 1
  )
  calib_results_lasso[[i]] <- calib_data_lasso %>%
    group_by(bin) %>%
    summarise(
      observed = mean(class),
      predicted = mean(prob),
      se = sqrt(observed * (1 - observed) / n())
    )
}


```

```{r}
# Extract numeric AUC values from the list of AUC objects
auc_numeric_enet <- sapply(auc_values_enet, function(x) as.numeric(x))
auc_numeric_lasso <- sapply(auc_values_lasso, function(x) as.numeric(x))

# Compute the mean AUC
mean_auc_enet <- mean(auc_numeric_enet)
mean_auc_lasso <- mean(auc_numeric_lasso)

```


```{r}
# Define a common set of specificity thresholds
common_specificities <- seq(0, 1, length.out = 100)

# Interpolate sensitivity for each ROC curve at the common specificities
interp_sensitivities_lasso <- sapply(roc_results_lasso, function(roc_data) {
  approx(x = roc_data$Specificity, y = roc_data$Sensitivity, xout = common_specificities)$y
})

# Compute the mean sensitivity across imputations
mean_sensitivity_lasso <- rowMeans(interp_sensitivities_lasso, na.rm = TRUE)

# Create a data frame for the averaged ROC curve
mean_roc_lasso <- data.frame(
  Specificity = common_specificities,
  Sensitivity = mean_sensitivity_lasso
)

# Plot the averaged ROC curve
ROC_lasso = ggplot(mean_roc_lasso, aes(x = 1 - Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, label = paste("Mean AUC =", round(mean_auc_lasso, 2)), size = 3, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal()

```

```{r}
# Define a common set of specificity thresholds
common_specificities <- seq(0, 1, length.out = 100)

# Interpolate sensitivity for each ROC curve at the common specificities
interp_sensitivities_enet <- sapply(roc_results_enet, function(roc_data) {
  approx(x = roc_data$Specificity, y = roc_data$Sensitivity, xout = common_specificities)$y
})

# Compute the mean sensitivity across imputations
mean_sensitivity_enet <- rowMeans(interp_sensitivities_enet, na.rm = TRUE)

# Create a data frame for the averaged ROC curve
mean_roc_enet <- data.frame(
  Specificity = common_specificities,
  Sensitivity = mean_sensitivity_enet
)

# Plot the averaged ROC curve
ROC_enet = ggplot(mean_roc_enet, aes(x = 1 - Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, label = paste("Mean AUC =", round(mean_auc_enet, 2)), size = 3, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal()

```


```{r}
# Combine Calibration Results Across Imputations
calib_combined_enet <- do.call(rbind, calib_results_enet) %>%
  group_by(bin) %>%
  summarise(
    observed = mean(observed),
    predicted = mean(predicted),
    se = sqrt(sum(se^2) / n())
  )

calib_combined_lasso <- do.call(rbind, calib_results_lasso) %>%
  group_by(bin) %>%
  summarise(
    observed = mean(observed),
    predicted = mean(predicted),
    se = sqrt(sum(se^2) / n())
  )

```

```{r}
num_cuts <- 10  # Number of bins for calibration

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_combined_lasso, span = 0.75)
calib_combined_lasso$loess_pred <- predict(loess_fit, calib_combined_lasso$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_lasso = ggplot(calib_combined_lasso) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se,
                    ymax = observed + 1.96 * se),
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence") +
  #       title = "Calibration Plot for Elastic Net Model with Error Bars"
  theme_minimal()


# Plot Calibration Curve with Loess
calib_combined_lasso <- calib_combined_lasso %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_lasso = ggplot(calib_combined_lasso, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "slateblue3", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  scale_color_manual(values = c("Ideal" = "red",
                                "Flexible calibration" = "slateblue3")) +
  scale_linetype_manual(values = c("Ideal" = "solid",
                                   "Flexible calibration" = "dashed")) +
  labs(x = "Predicted Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence",
       color = "Legend", linetype = "Legend") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```


```{r}
num_cuts <- 10  # Number of bins for calibration

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_combined_enet, span = 0.75)
calib_combined_enet$loess_pred <- predict(loess_fit, calib_combined_enet$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_enet = ggplot(calib_combined_enet) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se,
                    ymax = observed + 1.96 * se),
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence") +
  #       title = "Calibration Plot for Elastic Net Model with Error Bars"
  theme_minimal()


# Plot Calibration Curve with Loess
calib_combined_enet <- calib_combined_enet %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_enet = ggplot(calib_combined_enet, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "slateblue3", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  scale_color_manual(values = c("Ideal" = "red",
                                "Flexible calibration" = "slateblue3")) +
  scale_linetype_manual(values = c("Ideal" = "solid",
                                   "Flexible calibration" = "dashed")) +
  labs(x = "Predicted Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence",
       color = "Legend", linetype = "Legend") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```


```{r, fig.width = 10, fig.height = 6, out.width="90%", fig.align='center'}

plots_enet = arrangeGrob(
  calib_error_bar_enet, calib_loess_enet,  ROC_enet,
  ncol = 3,
  top = textGrob("Elastic Net Regression",
                 gp = gpar(fontface = "bold", fontsize = 14)
))

plots_lasso = arrangeGrob(
  calib_error_bar_lasso, calib_loess_lasso, ROC_lasso,
  ncol = 3,
  top = textGrob("Lasso Regression",
                 gp = gpar(fontface = "bold", fontsize = 14)
))

# Bold the main title
main_title <- textGrob(
  "Figure 2: Calibration Plots with Error Bars and LOESS and ROC Curves (Moderator Effects)",
  gp = gpar(fontsize = 16)
)

# Arrange everything with the bold title
grid.arrange(
  plots_lasso,
  plots_enet,
  nrow = 2,
  top = main_title
)
```



### Calibration Plots (Left Panel)

**Lasso Model** The calibration plot shows that the Lasso model’s predicted probabilities generally align with the observed smoking abstinence rates, but there is noticeable variability, especially at higher probability estimates. The model tends to slightly underpredict abstinence at lower probabilities and demonstrates a wider spread of actual values as probabilities increase.

**Elastic Model**

### LOESS-Smoothing Calibration Curves (Middle Panel)

**Lasso Model** The LOESS curve for the Lasso model shows underprediction of abstinence at lower probabilities, with the curve staying below the ideal line at the low end. The model’s predictions improve slightly as probabilities increase but still demonstrate some deviation, indicating inconsistencies in predicted abstinence probability across ranges.

**Elastic Model** 

### ROC Curves (Right Panel)

**Lasso Model** The ROC curve for the Lasso model yields an AUC of 0.74, indicating that this model has the best discrimination ability among the three models. It suggests that the Lasso model can effectively distinguish between abstinent and non-abstinent individuals.

**Elastic Model**


For the second objective, we explored baseline characteristic as potential predictors. Overall, we followed similar analysis procedure as in objective one, but due to lower model complexity, we could employ exhaustive replacement in best subset selection. Table 5 compares the coefficients of variables selected by the three different modeling approaches and their corresponding ORs. On this approach, we observed that three variables (ftcd_score, mde_curr and NMR) were present in all three models. As previously discussed, FTCD score and NMR could be potentional predictors for predicting the outcome.  Also, the OR of mde_curr is less than 1 in all three methods, meaning mde_curr has a similar behavior with ftcd_score. This means that participants with current MDD would have a lower success rate of smoking abstinence than those with past MDD. Finally, Var has a consistently >1 OR in all three methods used, while BA did not show a positive impact on abstinence, which is consistent with the findings from the original study (@hitsman2023efficacy).

```{r}
### Second objective - Predictors

predictor_names <- c("Var", "BA", "age_ps", "sex_ps", "inc", "edu_merged", "race",
                     "ftcd_score", "ftcd.5.mins", "bdi_score_w00", "cpd_ps",
                     "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",
                     "shaps_score_pq1", "otherdiag", "antidepmed", "mde_curr",
                     "NMR", "Only.Menthol", "readiness")

# Lasso Regression
# To identify the potential interaction terms for moderator effects
train_predictors_dummy_include_names <- c(
  "Var1", "BA1", "age_ps", "sex_ps2", "inc2", "inc3",
  "inc4", "inc5", "edu_merged2", "edu_merged3",
  "raceBlack", "raceHispanic", "raceOther",
  "ftcd_score", "ftcd.5.mins1", "bdi_score_w00", "cpd_ps",
  "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",
  "shaps_score_pq1", "otherdiag1", "antidepmed1",
  "mde_curr1", "NMR", "Only.Menthol1",
  "readiness"
)

# Helper function to perform model fitting
 fit_models <- function(data) {
   # Define predictors and outcome
   outcome <- data$abst
   
   predictors <- data[, predictor_names]
   # for Lasso (to break down factors with >2 levels)
   predictors_dummy <- model.matrix( ~ 0 + ., data = predictors)
   # remove the extra reference group
   predictors_dummy <- predictors_dummy[, -which(colnames(predictors_dummy) ==
                                                   "Var0")]
   
 

  # Split into train and test sets
   set.seed(58)
   train_index <- createDataPartition(outcome, p = 0.7, list = FALSE)
   train_data <- data[train_index, ]
   train_outcome = train_data$abst
   test_data <- data[-train_index, ]
   test_outcome = test_data$abst
   
   train_predictors_dummy <- predictors_dummy[train_index, ]
   test_predictors_dummy <- predictors_dummy[-train_index, ]
   
   train_predictors_dummy_include =
     train_predictors_dummy[, train_predictors_dummy_include_names]
   test_predictors_dummy_include =
     test_predictors_dummy[, train_predictors_dummy_include_names]

  # Set penalty factors to enforce keeping Var and BA
  # Initialize penalty factors to 1 for all variables
  penalty_factors <- rep(1, ncol(train_predictors_dummy_include))

  # Identify columns corresponding exactly to "Var1" and "BA1" (not their interactions)
  var1_col <- grep("^Var1$", colnames(train_predictors_dummy_include))
  ba1_col <- grep("^BA1$", colnames(train_predictors_dummy_include))
 
  penalty_factors[c(var1_col, ba1_col)] <- 0
  names(penalty_factors) <- colnames(train_predictors_dummy_include)

  # Fit Elastic Net model
  enet_model <- cv.glmnet(
    as.matrix(train_predictors_dummy_include),
    train_outcome,
    penalty.factor = penalty_factors,
    alpha = 0.5,
    family = "binomial",
    nfold = 10
  )

  # Fit Lasso model (alpha = 1)
  lasso_model <- cv.glmnet(
    as.matrix(train_predictors_dummy_include),
    train_outcome,
    penalty.factor = penalty_factors,
    alpha = 1,
    family = "binomial",
    nfold = 10
  )

  list(
    elastic_net = enet_model,
    lasso = lasso_model
  )
}
```

```{r}
# Fit models across imputed datasets
aim2_results <- list()
for (i in 1:5) {
  dataset <- complete(data_mice, action = i)
  aim2_results[[i]] <- fit_models(dataset)
}
```



```{r}
# Initialize lists to store coefficients for Elastic Net and Lasso
elastic_net_coefs <- lapply(aim2_results, function(res) coef(res$elastic_net, s = res$elastic_net$lambda.min))
lasso_coefs <- lapply(aim2_results, function(res) coef(res$lasso, s = res$lasso$lambda.min))


# Function to process coefficients for averaging and selection count
process_coefs <- function(coefs_list) {
  # Combine coefficients into a matrix
  coefs_matrix <- do.call(cbind, lapply(coefs_list, function(coef) as.numeric(coef)))
  rownames(coefs_matrix) <- rownames(coefs_list[[1]])
 
  # Count non-zero selections for each variable
  selection_counts <- rowSums(coefs_matrix != 0)
 
  # Compute the average of coefficients only when selected (non-zero)
  averaged_coefs <- rowSums(coefs_matrix) / selection_counts
  averaged_coefs[is.na(averaged_coefs)] <- 0  # Handle cases where selection_counts is 0
 
  # Create result table
  result_table <- data.frame(
    variable = rownames(coefs_matrix),
        SelectionTimes = selection_counts,
    AverageCoefficient = averaged_coefs
  ) %>%
    filter(SelectionTimes > 0)  # Keep only variables selected at least once
 
  return(result_table)
}

# Process Elastic Net and Lasso coefficients
result_table_enet <- process_coefs(elastic_net_coefs)
result_table_lasso <- process_coefs(lasso_coefs)

# Display the results
# result_table_enet
# result_table_lasso

```


```{r}
# Summary table of coef
large_threshold <- 100

# Calculate OR for each coefficient for each method and rename columns correctly
enet_df <- result_table_enet %>%
  rename(`Selection Times` = SelectionTimes) %>%
  rename(`Elastic Net Average Coef` = AverageCoefficient) %>%
  mutate(`Elastic Net Average OR` = exp(`Elastic Net Average Coef`))

lasso_df <- result_table_lasso %>%
  rename(`Selection Times` = SelectionTimes) %>%
  rename(`Lasso Average Coef` = AverageCoefficient) %>%
  mutate(`Lasso OR` = exp(`Lasso Average Coef`))



# Merge all data frames based on variable names
combined_df <- full_join(lasso_df, enet_df, by = "variable") %>%
  mutate(across(where(is.numeric), ~ round(.x, 4))) %>%
  mutate(across(where(is.numeric), ~ ifelse(as.numeric(.) > large_threshold, "*", .)))

# Remove the intercept row
combined_df <- combined_df[combined_df$variable != "(Intercept)", ]

# Standardize interaction terms by sorting them alphabetically
combined_df <- combined_df %>%
  mutate(
    variable = sapply(variable, function(x) {
      terms <- unlist(strsplit(x, ":"))
      if (length(terms) > 1) {
        paste(sort(terms), collapse = ":")
      } else {
        x
      }
    })
  )

# Combine rows with the same standardized interaction term names
combined_df <- combined_df %>%
  group_by(variable) %>%
  summarize(across(everything(), ~ ifelse(is.numeric(.), sum(as.numeric(.), na.rm = TRUE), .))) %>%
  ungroup()

# Replace zeroes and any remaining NAs with an empty space for readability
combined_df <- combined_df %>%
  mutate(across(where(is.numeric), ~ ifelse(. == 0, "", .))) %>%
  replace(is.na(.), " ")

# Display the final combined table with grouped headers
combined_df %>%
  kable(row.names = F,
        col.names = c("Variable", "Selection Times","Average Coef", "OR", "Selection Times", "Average Coef", "OR"),
        caption = "Summary of Average Coefficients and Odds Ratios for Potential Predictor Effects across Model Selection Methods") %>%
  add_header_above(c(" " = 1, "Lasso" = 3, "Elastic Net" = 3)) %>%
  kable_styling(full_width = F, position = "center", font_size = 9)

```


```{r}
# Initialize lists to store results for each imputation
roc_results_enet <- list()
calib_results_enet <- list()
auc_values_enet <- list()

roc_results_lasso <- list()
calib_results_lasso <- list()
auc_values_lasso <- list()

num_cuts <- 10  # Number of bins for calibration

for (i in 1:5) {
  dataset <- complete(data_mice, action = i)
 
  # Split the dataset into training and test sets
  set.seed(58)
  train_index <- createDataPartition(dataset$abst, p = 0.7, list = FALSE)
  train_data <- dataset[train_index, ]
  test_data <- dataset[-train_index, ]
 
  # Prepare predictors and outcome for test set
  test_variables_dummy <- model.matrix(~ 0 + ., data = test_data[, predictor_names])
  test_variables_dummy <- test_variables_dummy[, -which(colnames(test_variables_dummy) == "Var0")]
  test_variables_dummy_full_interactions <- model.matrix(~ . ^ 2, data = as.data.frame(test_variables_dummy))
  test_variables_dummy_include <- test_variables_dummy_full_interactions[, train_predictors_dummy_include_names]
  test_outcome <- test_data$abst

  # Predict probabilities for Elastic Net
  predicted_prob_enet <- as.numeric(predict(aim2_results[[i]]$elastic_net,
                                            newx = as.matrix(test_variables_dummy_include),
                                            s = "lambda.min", type = "response"))
 
  # Predict probabilities for Lasso
  predicted_prob_lasso <- as.numeric(predict(aim2_results[[i]]$lasso,

                                             newx = as.matrix(test_variables_dummy_include),
                                             s = "lambda.min", type = "response"))

  # Compute ROC and AUC for Elastic Net
  roc_enet <- roc(test_outcome, predicted_prob_enet)
  roc_results_enet[[i]] <- data.frame(
    Specificity = rev(roc_enet$specificities),
    Sensitivity = rev(roc_enet$sensitivities)
  )
  auc_values_enet[[i]] <- auc(roc_enet)  # Store AUC separately
 
  # Compute ROC and AUC for Lasso
  roc_lasso <- roc(test_outcome, predicted_prob_lasso)
  roc_results_lasso[[i]] <- data.frame(
    Specificity = rev(roc_lasso$specificities),
    Sensitivity = rev(roc_lasso$sensitivities)
  )
  auc_values_lasso[[i]] <- auc(roc_lasso)  # Store AUC separately

 
  # Calibration for Elastic Net
  calib_data_enet <- data.frame(
    prob = predicted_prob_enet,
    bin = cut(predicted_prob_enet, breaks = num_cuts),
    class = as.numeric(test_outcome) - 1
  )
  calib_results_enet[[i]] <- calib_data_enet %>%
    group_by(bin) %>%
    summarise(
      observed = mean(class),
      predicted = mean(prob),
      se = sqrt(observed * (1 - observed) / n())
    )
 
  # Calibration for Lasso
  calib_data_lasso <- data.frame(
    prob = predicted_prob_lasso,
    bin = cut(predicted_prob_lasso, breaks = num_cuts),
    class = as.numeric(test_outcome) - 1
  )
  calib_results_lasso[[i]] <- calib_data_lasso %>%
    group_by(bin) %>%
    summarise(
      observed = mean(class),
      predicted = mean(prob),
      se = sqrt(observed * (1 - observed) / n())
    )
}


```

```{r}
# Extract numeric AUC values from the list of AUC objects
auc_numeric_enet <- sapply(auc_values_enet, function(x) as.numeric(x))
auc_numeric_lasso <- sapply(auc_values_lasso, function(x) as.numeric(x))

# Compute the mean AUC
mean_auc_enet <- mean(auc_numeric_enet)
mean_auc_lasso <- mean(auc_numeric_lasso)

```


```{r}
# Define a common set of specificity thresholds
common_specificities <- seq(0, 1, length.out = 100)

# Interpolate sensitivity for each ROC curve at the common specificities
interp_sensitivities_lasso <- sapply(roc_results_lasso, function(roc_data) {
  approx(x = roc_data$Specificity, y = roc_data$Sensitivity, xout = common_specificities)$y
})

# Compute the mean sensitivity across imputations
mean_sensitivity_lasso <- rowMeans(interp_sensitivities_lasso, na.rm = TRUE)

# Create a data frame for the averaged ROC curve
mean_roc_lasso <- data.frame(
  Specificity = common_specificities,
  Sensitivity = mean_sensitivity_lasso
)

# Plot the averaged ROC curve
ROC_lasso = ggplot(mean_roc_lasso, aes(x = 1 - Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, label = paste("Mean AUC =", round(mean_auc_lasso, 2)), size = 3, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal()

```

```{r}
# Define a common set of specificity thresholds
common_specificities <- seq(0, 1, length.out = 100)

# Interpolate sensitivity for each ROC curve at the common specificities
interp_sensitivities_enet <- sapply(roc_results_enet, function(roc_data) {
  approx(x = roc_data$Specificity, y = roc_data$Sensitivity, xout = common_specificities)$y
})

# Compute the mean sensitivity across imputations
mean_sensitivity_enet <- rowMeans(interp_sensitivities_enet, na.rm = TRUE)

# Create a data frame for the averaged ROC curve
mean_roc_enet <- data.frame(
  Specificity = common_specificities,
  Sensitivity = mean_sensitivity_enet
)

# Plot the averaged ROC curve
ROC_enet = ggplot(mean_roc_enet, aes(x = 1 - Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, label = paste("Mean AUC =", round(mean_auc_enet, 2)), size = 3, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal()

```


```{r}
# Combine Calibration Results Across Imputations
calib_combined_enet <- do.call(rbind, calib_results_enet) %>%
  group_by(bin) %>%
  summarise(
    observed = mean(observed),
    predicted = mean(predicted),
    se = sqrt(sum(se^2) / n())
  )

calib_combined_lasso <- do.call(rbind, calib_results_lasso) %>%
  group_by(bin) %>%
  summarise(
    observed = mean(observed),
    predicted = mean(predicted),
    se = sqrt(sum(se^2) / n())
  )

```

```{r}
num_cuts <- 10  # Number of bins for calibration

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_combined_lasso, span = 0.75)
calib_combined_lasso$loess_pred <- predict(loess_fit, calib_combined_lasso$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_lasso = ggplot(calib_combined_lasso) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se,
                    ymax = observed + 1.96 * se),
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence") +
  #       title = "Calibration Plot for Elastic Net Model with Error Bars"
  theme_minimal()


# Plot Calibration Curve with Loess
calib_combined_lasso <- calib_combined_lasso %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_lasso = ggplot(calib_combined_lasso, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "slateblue3", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  scale_color_manual(values = c("Ideal" = "red",
                                "Flexible calibration" = "slateblue3")) +
  scale_linetype_manual(values = c("Ideal" = "solid",
                                   "Flexible calibration" = "dashed")) +
  labs(x = "Predicted Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence",
       color = "Legend", linetype = "Legend") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```


```{r}
num_cuts <- 10  # Number of bins for calibration

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_combined_enet, span = 0.75)
calib_combined_enet$loess_pred <- predict(loess_fit, calib_combined_enet$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_enet = ggplot(calib_combined_enet) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se,
                    ymax = observed + 1.96 * se),
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence") +
  #       title = "Calibration Plot for Elastic Net Model with Error Bars"
  theme_minimal()


# Plot Calibration Curve with Loess
calib_combined_enet <- calib_combined_enet %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_enet = ggplot(calib_combined_enet, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "slateblue3", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  scale_color_manual(values = c("Ideal" = "red",
                                "Flexible calibration" = "slateblue3")) +
  scale_linetype_manual(values = c("Ideal" = "solid",
                                   "Flexible calibration" = "dashed")) +
  labs(x = "Predicted Probability of Smoking Abstinence",
       y = "Actual Smoking Abstinence",
       color = "Legend", linetype = "Legend") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```


```{r, fig.width = 10, fig.height = 6, out.width="90%", fig.align='center'}

plots_enet = arrangeGrob(
  calib_error_bar_enet, calib_loess_enet,  ROC_enet,
  ncol = 3,
  top = textGrob("Elastic Net Regression",
                 gp = gpar(fontface = "bold", fontsize = 14)
))

plots_lasso = arrangeGrob(
  calib_error_bar_lasso, calib_loess_lasso, ROC_lasso,
  ncol = 3,
  top = textGrob("Lasso Regression",
                 gp = gpar(fontface = "bold", fontsize = 14)
))

# Bold the main title
main_title <- textGrob(
  "Figure 2: Calibration Plots with Error Bars and LOESS and ROC Curves (Predictor Effects)",
  gp = gpar(fontsize = 16)
)

# Arrange everything with the bold title
grid.arrange(
  plots_lasso,
  plots_enet,
  nrow = 2,
  top = main_title
)
```

# Conclusions and Limitations

This study underscores the potential benefits of tailored smoking cessation interventions for individuals with Major Depressive Disorder (MDD). Our analysis revealed that baseline characteristics, particularly FTCD score and Nicotine Metabolism Ratio (NMR), significantly impact abstinence outcomes. Higher nicotine dependence was associated with lower cessation success, while a higher NMR indicated a greater likelihood of quitting. These findings suggest that individualized treatments, incorporating both pharmacotherapy and behavioral strategies, may be more effective for this high-risk population.

The use of multiple modeling approaches— Lasso, Stepwise Logistic Regression, and Best Subset Selection— allowed for a robust evaluation of predictive factors, capturing both common and unique predictors across methods. While Behavioral Activation and varenicline showed mixed effects on abstinence rates, variability in predictor selection highlights the complexity of predicting cessation success in individuals with MDD. This suggests that integrating insights from different models can help identify a broader range of influential factors, enhancing the personalization of treatment approaches.

However, limitations of this study include a moderate sample size and reliance on self-reported smoking data, which may limit generalizability and introduce potential biases. Furthermore, the high number of interaction terms included in the full model for moderator effect exploration could introduce the issue of overfitting. Future research should expand on these findings by employing larger samples, objective measures of smoking, and long-term follow-up. Further exploration of additional predictors, such as genetic markers or psychiatric profiles, could provide deeper insights into treatment responses, ultimately guiding the development of optimized cessation strategies for those with MDD.


# Data Privacy and Code Availability

The analysis dataset was obtained by Dr. George Papandonatos from the Department of Biostatistics at Brown University and cannot be shared due to privacy. The replication code can be found at <https://github.com/AristofanisR/Practical_Data_Analysis_Project2>

\newpage

# References

::: {#refs}
:::

\newpage

# Code Appendix

```{r ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}
```
